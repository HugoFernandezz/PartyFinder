name: Scrape Events

on:
  # Ejecutar 3 veces al día: 10:00, 16:00, 22:00 (hora España)
  schedule:
    - cron: '0 9,15,21 * * *'
  
  # Permitir ejecución manual
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: backend/requirements.txt
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y xvfb chromium-browser
      
      - name: Install Python dependencies
        run: |
          cd backend
          pip install -r requirements.txt
      
      - name: Create data directory
        run: mkdir -p backend/data
      
      - name: Run scraper with virtual display
        env:
          FIREBASE_SERVICE_ACCOUNT: ${{ secrets.FIREBASE_SERVICE_ACCOUNT }}
          DISPLAY: ':99'
        run: |
          # Iniciar display virtual
          Xvfb :99 -screen 0 1920x1080x24 &
          sleep 3
          
          # Ejecutar scraper
          cd backend
          python scraper.py --firebase
      
      - name: Upload artifacts (backup)
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: scraped-data-${{ github.run_number }}
          path: backend/data/*.json
          retention-days: 7

  notify-on-failure:
    runs-on: ubuntu-latest
    needs: scrape
    if: needs.scrape.result == 'failure'
    
    steps:
      - name: Log failure
        run: |
          echo "Scraping failed at $(date)"
          echo "Check the workflow logs for details"

